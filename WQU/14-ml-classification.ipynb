{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb52e74-a0f8-485c-81eb-e734eb3fd39c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+3\"><strong>Machine Learning: Classification</strong></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a39aa45-1f4b-4f4b-be9a-8c58492d5bea",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from IPython.display import YouTubeVideo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1461057-1cce-48d4-a221-6c6679b0c5b2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9259c01-f18d-4fc9-9541-eec46e3c97e4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For the examples here, we'll look at buildings in the Ramechhap district of Nepal. (In our SQLite database, Ramechhap has the `district_id` of `1`.) Run the wrangle function below to connect to the SQLite database load the data into the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1824582-3230-4073-84cb-58970ce2870d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def wrangle(db_path):\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    # Construct query\n",
    "    query = \"\"\"\n",
    "        SELECT distinct(i.building_id) AS b_id,\n",
    "           s.*,\n",
    "           d.damage_grade\n",
    "        FROM id_map AS i\n",
    "        JOIN building_structure AS s ON i.building_id = s.building_id\n",
    "        JOIN building_damage AS d ON i.building_id = d.building_id\n",
    "        WHERE district_id = 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Read query results into DataFrame\n",
    "    df = ...\n",
    "\n",
    "    # Create binary target column\n",
    "    df[\"damage_grade\"] = df[\"damage_grade\"].str[-1]\n",
    "    df[\"damage_grade\"] = pd.to_numeric(df[\"damage_grade\"], errors=\"coerce\")\n",
    "    df[\"severe_damage\"] = (df[\"damage_grade\"] > 3).astype(int)\n",
    "\n",
    "    # Identify leaky columns\n",
    "    drop_cols = [col for col in df.columns if \"post_eq\" in col]\n",
    "\n",
    "    # Add high-cardinality / redundant column\n",
    "    \n",
    "\n",
    "    # Drop old target\n",
    "    drop_cols.append(\"damage_grade\")\n",
    "\n",
    "    # Drop multicollinearity column\n",
    "    drop_cols.append(\"count_floors_pre_eq\")\n",
    "\n",
    "    # Drop columns\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd896de7-0b86-4226-b610-f937d8bb1a0d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df = ...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc3e65-fe51-4882-b1e4-5ddefd3f5558",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Data Segregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2108f-8ed1-4d39-a878-c1f154ba415c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Training Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28845dde-6e55-46b5-8238-c37c333f254a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Randomized Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036047e7-c086-4c6f-ba10-39d473ec347b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Splitting a dataset** into different sets is an important part of the model development process. The initial dataset is typically split into **two** (**training** and **testing**) or **three** (**training**, **validation**, and **testing**) datasets. This helps ensure that the model can generalize. Usually, more data is used for training than for validation or testing. If splitting into two datasets, a good rule of thumb is to split your data randomly into a ratio of **80:20** training:testing. If splitting into three datasets, splitting the data into a ratio of **70:20:10** (training:validation:testing) is commonly used. \n",
    "\n",
    "Validation datasets are usually used to tune model hyperparameters. A hyperparameter is a model setting that can't be learned during model training and must be explicitly set. In contrast, a model parameter can be learned. An example of a hyperparameter is the depth of a decision tree . An example of a model parameter includes a coefficient of a variable from linear regression.\n",
    "\n",
    "In order to split our data, we'll be using the `train_test_split` function from scikit-learn. We'll begin by splitting our data into a training and testing set. Next, we'll apply the `train_test_split` function to our testing set to generate our validation dataset and new testing dataset. \n",
    "\n",
    "We will create a feature matrix X and target vector y. The target is \"severe_damage\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f01cea-ae1d-4ceb-a2cb-ab32997cbc34",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "target = \"severe_damage\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f9b1b9-1925-490b-95e6-7d2111e239d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Drop the target from the DataFrame and save the results into a X. Save the target column into y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf56500-f7a4-462a-a674-0b85c0eb1ef9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X = ...\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02f17a-d149-44f0-87ff-9310650fe0b5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finally, we will split our dataset into a training and test set using the `train_test_split` function from `scikit-learn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2c3ee3-5d5e-46e8-9b93-d47b6dc121bf",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53bad2c-09bd-4f53-92f1-d5a1c3b1b3ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374c060-3b31-4cf9-b473-34c8c5407e0b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice: Perform a randomized split using scikit-learn</font>\n",
    "\n",
    "Try it yourself! Use `train_test_split` to divide the training data (X_train and y_train) into training and validation sets using the same randomized train-test split function used previously. The validation data will be 20% of the previously constructed training data. Don't forget to set a random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffedcab4-1bfe-48b7-b6e9-e88a6a3c1d6f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770e7d4-151b-4a22-a403-5f41e1162b61",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f63c7-d3bf-4d88-a5e9-9ced9a6bde5c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Majority and Minority Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b50a94-7e19-4b7b-b2be-4672d91b7ba2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The majority class refers to whatever category in a binary target occurs most frequently, and the minority class refers to whatever category in a binary target occurs less frequently. Let's use the `value_counts` method to plot the relative frequency of the two plots with a bar chart.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d5322-3193-4e6e-abd1-21b6b2a08060",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True).plot(\n",
    "    kind=\"bar\", xlabel=\"Group\", ylabel=\"Relative Frequency\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e2e0dd-cc2e-4243-917e-4c9e9af59833",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Since the category 1 (`severe_damage` = True) occurs most frequently, this is the majority class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c656d-75ec-4f41-b670-27f9a05fe538",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Positive and Negative Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc840d-08a3-4db6-8ba8-c3e380f6d388",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Positive class** and **negative class** are the two possible labels for binary classification problems. For example, if we are classifying whether an email is spam or not, we can designate \"spam\" as the positive class and \"not spam\" as the negative class. For the example in the project, we have \"bankrupt\" as the positive class and \"not bankrupt\" as the negative class. Conventionally, we use `0` or `False` to represent negative class, and `1` or `True` to represent positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf7551-6290-464a-8417-bc18a5190341",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020af8bf-b606-42f0-a3d1-bd2e9cd25526",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Logistic Regression\n",
    "The logistic regression model is the classifier version of linear regression. It will predict probability values that can be used to assign class labels. The model works by taking the output of a linear regression model and feeding it into a sigmoid or logistic function. \n",
    "\n",
    "Why transform a linear model this way? Linear regression models are great for **regression** problems because they can give you predictions that range from negative infinity to positive infinity. However, the sigmoid function bounds predictions between 0 and 1, which we then treat as a probability. This allows us to use the model for **classification** problems. \n",
    "\n",
    "An example of the sigmoid function is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b8a482-eddb-462b-abad-3a367f62a945",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10, 10, 100)\n",
    "s = 1 / (1 + np.exp(-x))\n",
    "\n",
    "plt.plot(x, s)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$S(x)$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ee895-b8ec-4cbd-b98c-45371c8df4cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The following video summarizes the math behind logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea80c0-cfe7-497a-a27c-cd7a5f4fbd4f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"yIYKR4sgzI8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7090cb-4f58-441d-891a-990bdd579ce0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You can add the logistic regression as a named step in a model pipeline like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f7086-db33-4a5b-adb1-93e9c78eeb45",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(OneHotEncoder(), LogisticRegression(max_iter=1000))\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158262ba-42bc-4dc7-bfe0-290d8e912c8b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## High-cardinality Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa53e8a-791c-4c7e-a4d0-fc29054cb3ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Cardinality refers to the number of unique values in a categorical variable. High cardinality means the categorical features have a large number of unique values. These features often don't work well with either one hot encoding or ordinal encoding. There is no exact number of unique values that makes a feature high-cardinality, but if the value of the categorical feature is unique for almost all observations, it can usually be dropped. You can see the number of unique values in a variable by using the `value_counts` method. For example, to check the number of unique values in the `roof_type` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269af41-fa56-4c8d-817e-9ca689a8fc20",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df[\"roof_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af9852-1dd9-4ecc-8ad6-88cd64c9ff94",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "There are only three unique values, so we will leave the column in the DataFrame. \n",
    "\n",
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Try it yourself! Use `value_counts` to check the number of unique values in the `building_id` column. Remove the column in the wrangle function if it has a large number of unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d556be-8dd6-4b8c-b27f-8b571806f5e4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# REMOVE{\n",
    "# X_train[\"building_id\"].value_counts()\n",
    "# REMOVE }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f027492-db49-4b22-b716-cb83f5fcf2d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Classification with Tree-based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91128514-f355-4880-9570-796cb511e037",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c0383-d262-47c9-84a1-67f11b82f008",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Decision trees are a general class of machine learning models that are used for both classification and regression. The model resemble a tree, complete with branches and leaves. The model is essentially a series of questions with \"yes\" or \"no\" answers. The decision tree starts by checking whatever condition does the best job at correctly separating the data into the two classes in the binary target. It then progressively checks more conditions until it can predict an observation's label. They are popular because they are more flexible than linear models and intuitive in a way that makes them easy to explain to stakeholders who are not familiar with data science.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a6d61-e58a-4a66-9102-0e0fb30d49a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Decision trees pros and cons:\n",
    "\n",
    "| Pros | Cons | \n",
    "| --- | --- | \n",
    "| can be used for classification and regression | generalization: they are prone to overfitting |\n",
    "| handles both numerical and categorical data | robustness: small variations in data can result in a different tree |\n",
    "| models nonlinear relationships between the features and target | class imbalance: if one class is much larger than the other, the tree may be unbalanced |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbd116-826e-43e9-ba76-ec06ea143f18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The following video summarizes a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ab5149-2da2-4fc0-94b5-485ba26dafe6",
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/7VeUPuFGJHk\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x2b032adb430>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo(\"7VeUPuFGJHk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a724764-d8e2-4a63-bd03-07ab10a14e4b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We will fit a decision tree to the training data, using an ordinal encoder to encode the categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f509b-80a0-45c9-b10d-e256b5ac6315",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    OrdinalEncoder(), DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f618e5-9ebc-42de-834a-d63a85789ef3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173336c-a806-4260-8103-93ebef505bd2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Probability Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75e88b-e386-447c-b16d-72a40c9c71de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Sometimes a model makes the same prediction for the target of two observations, but is more certain about one prediction. This is the difference between the prediction and the prediction's associated probability. \n",
    "\n",
    "The `predict` method predicts the target of an unlabeled observation. The `predict_proba` outputs the probability that an unlabeled observation belongs to one of two classes in the target. Both methods work similarly. They each are run on the fitted model and take a set of features as their input. For example, if we want to see the associated predictions if we used the `X_train` as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db570ab9-aa09-4008-a355-b26754c55241",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13348a21-d09e-4dce-ae93-ff6c54b06628",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "And if we wanted to see the associated probabilities for these predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbd448-39b8-44a6-8761-9d9ba46210ed",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f0be4-1c69-4e4c-9880-5de223edb1f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Note that there are two probability estimates for each observation, one for the likelihood of each class in the target. The second probability is the likelihood that the unknown observation belongs to the class equal to 1 and the first probability is the likelihood that the unknown observation belongs to the class equal to 0. Whichever class's probability is higher is the predicted class from `predict`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b672cb-aebd-43eb-bbc6-c6a54d2d0432",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice: Generate probability estimates using a trained model in scikit-learn</font>\n",
    "\n",
    "Try it yourself! Use `predict_proba` to generate probability estimates for the observations in `X_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e7f93-9b7f-49e4-8a10-afd51612ac0f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Remove{\n",
    "model.predict_proba(X_test)\n",
    "# Remove}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32f9160-da0d-4fa5-9f43-e752a43cf251",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1790e-91e8-487a-b48e-d6e18afa6ba3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Calculating Accuracy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0b1f3-6682-42f0-a346-a6287bb63303",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A natural choice for a metric for classification is accuracy. Accuracy is equal to the number of observations you correctly classified over all observations. For example, if your model properly identified 77 out of 100 images, you have an accuracy of 77%. Accuracy is an easy metric to both understand and calculate. Mathematically, it is simply\n",
    "\n",
    "$$ \\frac{\\text{number of correct observations}}{\\text{number of observations}}.$$\n",
    "\n",
    "Model accuracy can be calculated using the `accuracy_score` function. The function requires two arguments, the true labels and the predicted labels. For example, if we want to calculate the model accuracy score on the training data:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7068a-9c5a-40b8-9bb0-305741892c63",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "acc_train = accuracy_score(y_train, model.predict(X_train))\n",
    "print(\"Training Accuracy:\", round(acc_train, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a4bcf-d09f-406d-8388-59e534231d49",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice: Calculate the accuracy score for a model in scikit-learn</font>\n",
    "\n",
    "Try it yourself! Calculate the model's accuracy on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e1145-b377-4276-9cb5-a4af8bff04de",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "acc_val = ...\n",
    "print(\"Validation Accuracy:\", round(acc_val, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620cacb-da8e-4ea6-bdc4-ffc2e56506a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "### Baseline Accuracy Score\n",
    "\n",
    "How do you know whether or not the accuracy score you calculated for your model is good? A baseline accuracy score for the model can be used to compare your model accuracy results against. A common baseline is to use the percentage that the majority class shows up in the training data. This would be your accuracy if you simply predicted the majority class for all observations. If the model is not beating this baseline, that suggests that the features are not adding any valuable information to classify your observations. \n",
    "\n",
    "We can use the `value_counts` method with the `normalize = True` argument to calculate the baseline accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8fec6f-2511-47af-829e-8a607fd99100",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "acc_baseline = y_train.value_counts(normalize=True).max()\n",
    "print(\"Baseline Accuracy:\", round(acc_baseline, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d4d0e-2548-4e7c-ad26-cab65269a65d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8610a5b-5db4-4d62-9f4c-eda2b8649fcf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Accuracy score may not provide enough information to assess how a model is performing because it only gives us an overall score. Also, imbalanced data can lead to a high accuracy score even when a model isn't particularly useful. If we want to know what fraction of all positive predictions were correct and what fraction of positive observations did we identify, we can use a **confusion matrix**.\n",
    "\n",
    "A confusion matrix is a table summarizing the performance of the model by enumerating true and false positives and the true and false negatives.\n",
    "\n",
    "|                     | Positive Observation     | Negative Observation    |\n",
    "|---------------------|:------------------------:|:-----------------------:|\n",
    "| **Positive Prediction** |     True Positive (`TP`)   | False Positive (`FP`)     |\n",
    "| **Negative Prediction** | False Negative (`FN`)      |     True Negative (`TN`)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3fbce-822c-4020-982c-e2d8b88969f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Refer to this video for more details in confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310026a-70bf-418f-8339-406c9d286ac2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"_cpiuMuFj3U\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba413c8-2db5-4522-a7e8-083644c39ce8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here is the code to get the confusion matrix in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf19a5e-300a-438f-809a-305f155d6bd1",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_train, model.predict(X_train))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7b881-6034-44a8-82e6-548ae9c0b509",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You can also use the heatmap to better visualize confusion matrix using `ConfusionMatrixDisplay`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e7633-4c96-4e3d-8238-35c241c5e600",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9954-5ecf-4895-a80a-3f70a6f4692e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Get confusion matrix for the validation set and display with `ConfusionMatrixDisplay`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617a3f67-7f03-428d-9841-9553fafb0f78",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "cm = ...\n",
    "\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2375b7fd-0aa1-4a73-8102-02f8d2f5cd27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Precision Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdd8b47-b957-4171-a439-3977a4d192d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Depending on the context of the problem, instead of knowing model performances in both classes, sometimes we are more interested in the results in positive class. That's when we use **precision**. Precision is the fraction of true positives over all positive predictions. It is a measure of how \"precise\" our model is with regard to labeling observations as positive. \n",
    "\n",
    "For example in Project 3, we try to predict whether a company will go bankrupt, with `\"bankrupt\"` as the positive class. Out of all positive predictions made by the model, some companies actually went bankrupt (True Positive `TP`), while others didn't (False Positive `FP`). Precision measures how many times model predicted positives (`TP`+`FP`) correctly (`TP`). The equation for precision is:\n",
    "\n",
    "$$ \\text{precision} = \\frac{\\text{TP}}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07780c39-4b79-4b1c-8d8d-090ee832ffd7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Using the data and model above, we can get a precision score using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85c9ec-fdaf-4fb0-9067-b5e5d44658de",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_train, model.predict(X_train))\n",
    "\n",
    "print(f\"Training Set Precision is {round(precision,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f03a0f-5f2a-43ba-b7aa-73f7fbaacecc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Get precision for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7117b8e-7b18-45d7-a704-c05bebdc1f9d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "precision_val = ...\n",
    "print(f\"Validation Set Precision is {round(precision_val, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddd170-c023-4471-8834-7ccbc2305342",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Recall Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e1d40-ef77-402d-8e08-2f9ef37d5f70",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What if we care more about the model performance in the negative class? In this case, we need to calculate **recall**. Recall the fraction of true positives over all positive observations. It is a measure of our model's ability to \"catch\" and properly label observations that are positive. \n",
    "\n",
    "Let's return to the Poland bankruptcy example. Of all the companies that actually went bankrupt (`TP`+`FN`), how many companies did out model predict as going bankrupt (`TP`)? That's what recall measures. The equation to calculate recall is:\n",
    "\n",
    "$$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce07482-da2d-4d59-88b4-aec887eb9a4a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here is the code to calculate recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c0608-6e68-449f-8713-5ca05a6d86b6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall = recall_score(y_train, model.predict(X_train))\n",
    "\n",
    "print(f\"Training Set Recall is {round(recall, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d4c3e3-e271-4e8d-9aeb-bbd5c0d37ac3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Get precision for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc057737-3790-4df2-93c2-fc61c2e0c3ec",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "recall_val = ...}\n",
    "print(f\"Validation Set Precision is {round(recall_val, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2fc02d-ce8d-466c-93f4-e69e91d34af5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026fa0c-a314-4ec5-9777-089dc537d8fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can also use a **classification report** to look at the whole picture of the classification model performances. A classification report includes precision, recall, **F1 score** and **support**. We already know the first two, but F1 score is the harmonic mean of precision and recall, it equation is:\n",
    "\n",
    "$$ \\text{F1} = 2 \\left( \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}} \\right)$$\n",
    "\n",
    "Support number of observations for each class, thus it is useful to understand whether the data is imbalanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc77987-7626-47fd-b05c-d1fc4ec50e7f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_train, model.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abc46b-a228-4bd6-9ace-e0e531b3bcce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Note in the last two rows, we have the macro and the weighted average,. Macro average is the arithmetic average of a metric between the two classes:\n",
    "\n",
    "$$ \\text{0.65} = \\frac{0.70+0.60}{2} $$\n",
    "\n",
    "The weighted average is calculated as:\n",
    "\n",
    "$$ \\frac{\\sum(\\text{metric of interest} \\cdot \\text{weight})}{\\sum(\\text{weights})} $$\n",
    "\n",
    "Here the weights are the number of observation for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadedbc3-fa87-4e4d-9f92-4e09181c52d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here you may notice there are two rows of metrics. If you refer back to what we calculated previous on precision and recall, the second row actually align with what we found. That's because we usually define class one as the **positive class**, thus we are referring class 1's metric performance as the true precision and recall value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac6b51-8d51-4b5f-8d65-6659822adefe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Get classification report for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe0843-cf86-4b26-af7f-f889e9b49d04",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de12dc1-75a9-446a-ae40-76137f50a802",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14289438-3145-4f0e-bccf-ff78865e4be5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Plotting a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439a7c3-8622-4ecb-b76e-70f23bd0e354",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The `plot_tree` function can be used to a plot a decision tree. The visualization is fit to the size of the axis set with `matplotlib`. Use the `figsize` argument of `plt.subplots` to control the size of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5dbf38-30da-4069-9e67-d4685d0b68a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We'll demonstrate how to use the `plot_tree` function to graphically display a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a34cb8-2f96-4d8a-85d1-9ca877d5a45d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create larger figure\n",
    "fig, ax = plt.subplots(figsize=(25, 12))\n",
    "\n",
    "# Plot tree\n",
    "plot_tree(\n",
    "    decision_tree=...,\n",
    "    feature_names=...,\n",
    "    filled=True,  # Color leaf with class\n",
    "    rounded=True,  # Round leaf edges\n",
    "    proportion=True,  # Display proportion of classes in leaf\n",
    "    max_depth=3,  # Only display first 3 levels\n",
    "    fontsize=12,  # Enlarge font\n",
    "    ax=ax,  # Place in figure axis\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333ff0c7-71fe-4aee-b9ea-5593b0cd90f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice: Plot a decision tree using `scikit-learn`</font>\n",
    "\n",
    "Try it yourself! Use `plot_tree` to plot the decision tree from the `model` object, modifying the parameters of the tree to only display the first 3 levels and to not display the proportion of classes in a leaf.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cab4c7-11bf-4f33-b6db-56f672a8275b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create larger figure\n",
    "fig, ax = plt.subplots(figsize=(25, 12))\n",
    "\n",
    "# Plot tree\n",
    "plot_tree(\n",
    "    decision_tree=...,\n",
    "    feature_names=...,\n",
    "    filled=...,\n",
    "    rounded=...,\n",
    "    proportion=...,\n",
    "    max_depth=...,\n",
    "    fontsize=...,\n",
    "    ax=...,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d828b-e981-4ce1-83a6-0a1f389a5d39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The feature names and importance of features can be extracted from the column names in your training set. For the `importances`, you can access the [`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_) attribute of your model's `DecisionTreeClassifier`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8947e6-923b-43bd-9d15-ecdd0ad48fb9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "importances = model.named_steps[\"decisiontreeclassifier\"].feature_importances_\n",
    "\n",
    "print(\"Features:\", features[:3])\n",
    "print(\"Importances:\", importances[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc173066-018f-47f8-92ae-efa2928d551c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The importance of a feature is based on how well the feature correctly classifies observations. In a decision tree, this is on average how much a feature reduces the impurity metric. The tree determines how to split based on an impurity function. The impurity function calculates how homogeneous observations are at a particular leaf node. Conditions that do a better job minimizing impurity are used to split first. The `sklearn.tree` algorithm uses the Gini impurity by default. The Gini impurity measures the probability of an incorrect classification in the model for each branch. It ranges from 0 to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac978f-fce2-443f-9813-71b23863de62",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's create a bar chart to plot each feature with its corresponding importance. To build this bar chart, we'll create a pandas Series named feat_imp, where the index is features and the values are your importances. The Series should be sorted from smallest to largest importance so that the bar chart is also in order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b745cd8-c923-47ff-b9fe-a8d60bcde8de",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "feat_imp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399cf794-983c-4d02-80dd-03f8cdb82ecb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Next, we'll use the series to build a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51cf84-981a-4fa7-a920-654b3e21f93e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "feat_imp.plot(kind=\"barh\")\n",
    "plt.xlabel(\"Gini Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c8317-b9af-4818-84c2-91d1c1d8909d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Classification with Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d084b-3bbe-4211-8433-7dc6f9b2fde5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Ensemble models are machine learning models that use more than one predictor to arrive at a prediction. A group of predictors form an _ensemble_. In general, ensemble models perform better than using a single predictor. There are three types of ensemble models: **bagging**, **boosting**, and **blending**. Of the three, decision trees are commonly used to construct bagging and boosting models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0cee7-6433-4fb5-afeb-468cf95faa41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6c692-7428-4e41-8873-ebb4f21c7bfd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The performance of a single decision tree will be limited. Instead of relying on one tree, a better approach is to aggregate the predictions of multiple trees. On average, aggregation will perform better than a single predictor. You can envision the aggregation as mimicking the idea of \"wisdom of the crowd.\" We call a tree based model that aggregates the predictions of multiple trees a **random forest**.\n",
    "\n",
    "In order for a random forest to be effective, the model needs a diverse collection of trees. There should be variations in the chosen thresholds for splitting and the number of nodes and branches. There is no point in aggregating the predicted results if all the trees are nearly identical and produce the same result. There is no \"wisdom of the crowd\" if everyone thinks alike. To achieve a diverse set of trees, we need to:\n",
    "\n",
    "1. Train each tree in the forest using a different subset of the training set.\n",
    "1. Only consider a subset of features when deciding how to split the nodes.\n",
    "\n",
    "On the first point, we would ideally generate a new training set for each tree. However, oftentimes it's too difficult or expensive to collect more data, so we have to make do with what we have. Bootstrapping is a general statistical technique to generate \"new\" data sets with a single set by random sampling with _replacement_. Sampling with replacement allows for a data point to be sampled more than once.\n",
    "\n",
    "Typically, when training the standard decision tree model, the algorithm will consider all features in deciding the node split. Considering only a subset of your features ensures that your trees do not resemble each other. If the algorithm had considered all features, a dominant feature would be continuously chosen for node splits.\n",
    "\n",
    "The hyperparameters available for random forests include those of decision tress with some additions.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<th style=\"text-align: left\">Hyperparameter</th>\n",
    "<th style=\"text-align: left\">Description</th>\n",
    "</tr>\n",
    "    \n",
    "<tr>\n",
    "<td style=\"text-align: left\"><code>n_estimators</code></td>\n",
    "<td style=\"text-align: left\">The number of trees in the forest</td>\n",
    "</tr>\n",
    "\n",
    "<tr style=\"text-align: left\">\n",
    "<td style=\"text-align: left\"><code>max_samples</code></td>\n",
    "<td style=\"text-align: left\">If bootstrap is True, the number of samples to draw from X to train each base estimator</td>\n",
    "</tr>\n",
    "\n",
    "<tr style=\"text-align: left\">\n",
    "<td style=\"text-align: left\"><code>max_features</code></td>\n",
    "<td style=\"text-align: left\">The number of features to consider when looking for the best split</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td style=\"text-align: left\"><code>n_jobs</code></td>\n",
    "<td style=\"text-align: left\">The number of jobs to run in parallel when fitting and predicting</td>\n",
    "</tr>\n",
    "\n",
    "<tr style=\"text-align: left\">\n",
    "<td style=\"text-align: left\"><code>warm_start</code></td>\n",
    "<td style=\"text-align: left\">If set to <code>True</code>, reuse the trained tree from a prior fitting and just train the additional trees</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Since the random forest is based on idea of bootstrapping and aggregating the results, it is referred to as a **bagging** ensemble model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2d013-4335-4b4a-9a5c-2a99812b584f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Gradient Boosting Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96af308-0f2e-440d-8982-d630c95eb98c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Gradient boosting trees is another ensemble model. It uses a collection of tree models arranged in a sequence. Here, the model is built stage-wise; each additional tree aims to correct the previous tree's incorrect. \n",
    "\n",
    "Where does the name *gradient* in gradient boosting trees come from? Gradient descent is a minimization algorithm that updates/improves the current answer by taking a step in the direction of minimizing the loss function. This is the same as the gradient boosting trees algorithm as it adds trees to minimize loss/improve model performance. The term **boosting** refers to the algorithm's ability to combine multiple weak models in sequence to form a stronger model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca7882-0b1c-42a2-a996-f44ba2fb33ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Gradient boosting trees have a similar set of hyperparameters as random forests but with some key additions.\n",
    "\n",
    "<table>\n",
    "\t<tr>\n",
    "    <th style=\"text-align: left\">Hyperparameter</th>\n",
    "    <th style=\"text-align: left\">Description</th>\n",
    "\t</tr>  \n",
    "    <tr>\n",
    "        <td style=\"text-align: left\"><code>learning_rate</code></td>\n",
    "        <td style=\"text-align: left\">Multiplicative factor of the tree's contribution to the model.</td>\n",
    "\t</tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left\"><code>subsample</code></td>\n",
    "        <td style=\"text-align: left\">Fraction of the training data to use when fitting the trees.</td>\n",
    "\t</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18130231-fa4f-42b8-9bee-8f25cded2e6d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The learning rate determines how much each tree affect the final outcome and is very important in model convergence. Thus it should be considered during hyperparameter tuning to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef7d0e-ebe2-449c-a14c-00b424366ba1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf0aa8-4efc-4140-b22f-5596935d0f73",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "When we defined our decision tree estimator, we chose how many layers the tree would have using the `max_depth` argument. More generally, when we instantiate any estimator, we can pass keyword arguments that will dictate its structure. The decision tree regressor accepts [12 different keyword arguments](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor). These arguments are called **hyperparameters**. This is in contrast to **parameters**, which are the numbers that our model uses to predict labels based on features. Hyperparameters are decided before training and dictate the model's structure. Parameters are optimized during training. Basically all models have hyperparameters. Even a simple linear regressor has a hyperparameter: `fit_intercept`.\n",
    "\n",
    "Since changing a hyperparameters will change the structure of the model, we should think of choosing hyperparameters as part of the model building process. We can usually use **cross validation** combined with **grid search** when looking for the best model with the right hyperparameters. This process is called **hyperparameter tuning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da785a-12de-43df-938d-1e960452b255",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b748ac-1fec-43e1-8d0e-d3b332d9de46",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "When trying out different hyperparameter settings for estimators (such as the `max_depth` for a random forest), there's a risk in using the test set to evaluate these settings. What happens is that your knowledge about the test set can leak into the model, and performance metrics no longer reflect the model's ability to generalize. \n",
    "\n",
    "The generalization problem can be solved adding an extra set called **validation set**. In this case, we train the model with the training set, then evaluate different hyperparameters using the validation set. If the model is performing well in both sets, finally we will evaluate the model on the test set.\n",
    "\n",
    "But there's a drawback to this strategy. The potential issue we may face dividing data into three sets is that we will reduce the number of samples available to fit and train the model. In addition, the model results will change with respect to difference choices of training and validation portions.\n",
    "\n",
    "The solution here is to use **cross validation** (CV for short). In this case, we will still use a test set, but a validation set is no longer needed. **k-fold CV** is the most used cross validation method(http://scikit-learn.org/stable/modules/cross_validation.html#k-fold). The algorithm divides the training set into $k$ small folds. For each fold $k$, we:\n",
    "\n",
    "1. Train the model using all the folds but one (i.e. $k-1$ folds) as training data;\n",
    "\n",
    "1. Validate the model using the remaining fold as if it were test data, and store the performance metric;\n",
    "\n",
    "This approach makes the best use of all the data we are given, so it's particularly useful when the sample size is small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09b8a3-7ed1-4bce-aa16-02bbcf482539",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Here is the code for conducting a 5-fold cross-validation and reporting the accuracy score for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b946ff1-fc2b-4d0d-932f-f343169ec172",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = make_pipeline(OneHotEncoder(), DecisionTreeClassifier())\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f98157-6f51-48a8-899d-4a3474a4d047",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"{round(scores.mean(),2)} accuracy with a standard deviation of {round(scores.std(),2)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0224f90-cd71-44e5-8064-ffd7cc9e3b4d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Perform 2-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4604b-ec99-4245-97ef-ee25c0c767e8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "clf = ...\n",
    "scores = ...\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf445b-8dbd-4f77-b8ec-005221e0b103",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c42a34-79ed-44fa-b70f-e45b32d91b1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Another a useful tool for comparing different hyperparameter values is `GridSearchCV`. There are two ideas behind `GridSearchCV`: first we split the data using k-fold cross-validation, and then we train and evaluate models with different hyperparameter settings selected from a grid of possible combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0aaf12-2f3e-44ef-84f3-b8735529b3ca",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "First, we need to define the hyperparameters we want to tune, and tuning in what range. Here we are using an example of searching the best value for the `max_depth` in decision tree model. Since we will be building a pipeline including a transformer and estimator, we need to specify `max_depth` comes from the estimator `decisiontreeclassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdec893-0809-4417-90bd-1b9fd8cc68f4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"decisiontreeclassifier__max_depth\": range(1, 15)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c755f5-4cce-4fcc-b75a-9a80d488d9ff",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The we define the pipeline and the model with `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c455a-dd77-4de6-a4d2-7c0cd27e77eb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "clf = make_pipeline(OneHotEncoder(), DecisionTreeClassifier())\n",
    "model = GridSearchCV(clf, param_grid=params, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffac4ca-a73a-492e-b732-96f5f124e956",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Lastly fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cd288-0671-48f1-afec-cd4b1833c2aa",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6dc56-83fc-4e6a-b2a5-942c02057e5d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can check the best parameters once the fitting process finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd63b8-863e-4ff6-b6d7-e6d539edc7f9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01ec81-04b0-45be-adf5-82bb265e8f21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<font size=\"+1\">Practice</font>\n",
    "\n",
    "Perform `GridSearchCV` on both `max_depth` and `criterion` for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778aba62-c32a-4e20-98b0-a7ecdad68ab1",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Define grid\n",
    "params = ...\n",
    "\n",
    "# Build classifier\n",
    "clf = ...\n",
    "\n",
    "# Build grid search model\n",
    "model = ...\n",
    "\n",
    "# Fit model to training data\n",
    "\n",
    "\n",
    "# Check the best hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5529225-2286-401a-a1dc-7c63f71c8a30",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# References & Further Reading\n",
    "\n",
    "- [`scikit-learn` documentation on decision tree classifier model object](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "- [`scikit-learn` documentation on decision tree plot](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html)\n",
    "- [`scikit-learn` documentation on decision tree math](https://scikit-learn.org/stable/modules/tree.html)\n",
    "- [`scikit-learn` confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    "- [`scikit-learn` precision score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    "- [`scikit-learn` recall score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n",
    "- [`scikit-learn` classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "-[`Youtube`Confusion Matrix](https://www.youtube.com/watch?v=_cpiuMuFj3U)\n",
    "- [`scikit-learn`Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "- [`scikit-learn`k-fold Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1da26-aa25-4b9f-b3e2-cd93bb9b2d1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright  2022 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "174ef937a28829811967978ceafd30b4556b1949c3c64fea724a28599c7d4227"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
